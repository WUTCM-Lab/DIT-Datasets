[中文](https://github.com/WUTCM-Lab/DIT-Datasets/blob/main/README.md) | English

## Cross-Modal Drone Image–Text Retrieval
The cross-modal drone image–text (DIT) retrieval task aims at using either text or drone images as queries to retrieve relevant drone images or corresponding text. For this task, WUTCM Laboratory established two DIT datasets: [ERA dataset and UDV dataset](https://pan.baidu.com/s/1q93nDKqymEIEX8tcMtMoZQ?pwd=6868) (access code：6868).

### ERA-DIT Dataset 
The ERA-DIT dataset contains 2864 samples from the [ERA dataset](https://lcmou.github.io/ERA_Dataset/), and each image size is 640×640 pixels.

### UDV-DIT Dataset
The UDV-DIT dataset contains 10,693 samples collected from the [VisDrone](https://github.com/VisDrone/VisDrone-Dataset) and [University-1652](https://github.com/layumi/University1652-Baseline) datasets and the Internet. These samples cover a variety of urban environments with different image sizes.

Related models: [Visual Contextual Semantic Reasoning (VCSR)](https://ieeexplore.ieee.org/abstract/document/10634572)

Huang J, Chen Y, Xiong S, et al. Visual Contextual Semantic Reasoning for Cross-Modal Drone Image-Text Retrieval[J]. IEEE Transactions on Geoscience and Remote Sensing, 2024.

### Acknowledge
<ul>
<li> [1] L. Mou, Y. Hua, P. Jin, and X. X. Zhu, “ERA: A dataset and deep learning benchmark for event recognition in aerial videos,” 2020, arXiv:2001.11394.</li>
<li> [2] P. Zhu et al., "Detection and tracking meet drones challenge," IEEE Trans. Pattern Anal.  Mach. Intell., vol. 44, no. 11, pp. 7380–7399, Nov. 2022, doi: 10.1109/TPAMI.2021.3119563.</li>
<li> [3] Z. Zheng, Y. Wei, and Y. Yang, "University-1652: A multi-view multisource benchmark for drone-based geo-localization," in Proc. 28th ACM Int. Conf. Multimedia, Seattle, WA, USA, C. W. Chen et al., Eds., Oct. 2020, pp. 1395–1403, doi: 10.1145/3394171.3413896</li>
</ul>
